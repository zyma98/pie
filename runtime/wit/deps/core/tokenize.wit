interface tokenize {

    use common.{model};

    // Retrieves the tokenizer associated with the given model
    get-tokenizer: func(queue: borrow<model>) -> tokenizer;

    // Tokenizer resource for encoding and decoding text
    resource tokenizer {

        // Converts input text into a list of token IDs
        tokenize: func(text: string) -> list<u32>;

        // Converts token IDs back into a decoded string
        detokenize: func(tokens: list<u32>) -> string;

        // Returns the tokenizer's vocabulary as a list of byte sequences (tokens)
        get-vocabs: func() -> tuple<list<u32>, list<list<u8>>>;

        // Returns the split regular expression used by the tokenizer
        get-split-regex: func() -> string;

        // Returns the special tokens recognized by the tokenizer
        get-special-tokens: func() -> tuple<list<u32>, list<list<u8>>>;
    }

}