# Docker config for PIE with Python backend
host = "0.0.0.0"
port = 8080
enable_auth = false
auth_secret = "hello"
verbose = true
log = "pie.log"

[[backend]]
backend_type = "python"
exec_path = "/workspace/backend/backend-python/server.py"
model = "llama-3.2-1b-instruct"
device = "cuda:0"
dtype = "bfloat16"
kv_page_size = 16
max_batch_tokens = 10240
max_dist_size = 32
max_num_kv_pages = 10240
max_num_embeds = 128
max_num_adapters = 32
max_adapter_rank = 8
gpu_mem_headroom = 10.0
