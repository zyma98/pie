---
title: Installation
description: Get Pie up and running in minutes
sidebar_position: 1
---

# Installation

Pie supports Linux (CUDA) and macOS (Metal). Choose the installation method that works best for you.

## Quick Install (PyPI)

The fastest way to get started:

```bash
# Linux/Windows (CUDA)
pip install "pie-server[cuda]"

# macOS (Apple Silicon)
pip install "pie-server[metal]"
```

## Install from Source

For development or to get the latest features:

```bash
git clone https://github.com/pie-project/pie.git && cd pie/pie

# Use uv to sync dependencies (recommended)
# Options: cu126, cu128, cu130, metal
uv sync --extra cu128
```

:::tip
When building from source, prefix all commands with `uv run` (e.g., `uv run pie serve`).
:::

## Initial Setup

After installation, initialize your configuration:

```bash
pie config init
```

This creates `~/.pie/config.toml` with default settings.

## Download a Model

Download a model from HuggingFace:

```bash
pie model download meta-llama/Llama-3.2-1B-Instruct
```

Or use any compatible model:

```bash
pie model download Qwen/Qwen2.5-0.5B-Instruct
```

## Verify Installation

Run a test prompt:

```bash
pie run text-completion -- --prompt "Hello, world!"
```

:::note
The first run may take longer due to JIT compilation.
:::

## Configuration

Edit `~/.pie/config.toml` to customize:

```toml
[engine]
host = "127.0.0.1"
port = 8080
enable_auth = true

[[model]]
hf_repo = "meta-llama/Llama-3.2-1B-Instruct"
device = ["cuda:0"]
```

View your current configuration:

```bash
pie config show
```

Update specific values:

```bash
pie config update --hf-repo "Qwen/Qwen2.5-7B-Instruct"
pie config update --device "cuda:0,cuda:1"
```

## Next Steps

- Read the [Overview](../overview/index.mdx) to understand Pie's architecture
- Follow the [Tutorial](../tutorial/1-quickstart.mdx) to learn the basics
- Explore the [CLI Reference](../cli.mdx) for all commands
